[Bernoulli 15(4), 2009, 1179–1189](http://isi.cbs.nl/bernoulli/)
[DOI: 10.3150/09-BEJ193](http://dx.doi.org/10.3150/09-BEJ193)

# Determining full conditional independence by low-order conditioning


DHAFER MALOUCHE

Unit´e Signaux et Syst`emes, Ecole Nationale d’Ing´enieurs de Tunis BP 37, LE BELVEDERE
[1002, Tunis, Tunisia. E-mail: dhafer.malouche@essai.rnu.tn](mailto:dhafer.malouche@essai.rnu.tn)


A concentration graph associated with a random vector is an undirected graph where each
vertex corresponds to one random variable in the vector. The absence of an edge between any
pair of vertices (or variables) is equivalent to full conditional independence between these two
variables given all the other variables. In the multivariate Gaussian case, the absence of an edge
corresponds to a zero coefficient in the precision matrix, which is the inverse of the covariance
matrix.
It is well known that this concentration graph represents some of the conditional independencies in the distribution of the associated random vector. These conditional independencies
correspond to the “separations” or absence of edges in that graph. In this paper we assume that
there are no other independencies present in the probability distribution than those represented
by the graph. This property is called the perfect Markovianity of the probability distribution
with respect to the associated concentration graph. We prove in this paper that this particular
concentration graph, the one associated with a perfect Markov distribution, can be determined
by only conditioning on a limited number of variables. We demonstrate that this number is
equal to the maximum size of the minimal separators in the concentration graph.

Keywords: conditional independence; graphical models; Markov properties; separability in
graphs; undirected graphs


#### 1. Introduction

Let (X,G, F ) be a triple where X = ×α∈V Xα is a product probability space, G = (V,E)
is a graph with a finite set of vertices V and a set of edges E ⊆ V × V in which a certain
separation criteria C is defined, and F is a family of probability distribution of random
vectors X = (Xα,α ∈ V )[′] with values in X . The triple (X,G, F ) is called a graphical
model if it satisfies the following property called the global Markov property.
Let A, B and S be three disjoint subsets where A and B are non-empty. If S separates
A and B according to the criteria C in G, denoted by A⊥CB|S, then the random vectors
XA and XB are independent given XS, where XA, XB and XS are subvectors of X


1350-7265 ⃝c 2009 ISI/BS


-----



1180 D. Malouche

indexed respectively by the subsets of vertices A, B and S. So

A⊥CB|S then XA ⊥⊥ XB|XS. (1)

Note that the graph G should not contain loops – that is, an edge linking one vertex
to itself – and any pair of vertices in G is connected at maximum by one edge, that is,
there are no multiple edges between any given pair of vertices.
When the graph G has only undirected edges, that is,

(α,β) ∈ E ⇐⇒ (β,α) ∈ E,

the associated graphical model is called a concentration graph model (see Lauritzen
(1996)). Dempster (1972) studied concentration graph models for Gaussian distributions under the name of covariance selection or covariance selection models. The absence of an edge between a given pair of vertices (α,β) in the associated graph indicates that the random variable Xα is independent of Xβ given all the other variables
X−αβ = (Xγ,γ ̸= α,β)[′]. These models are very well studied, especially the ones corresponding to Gaussian distributions (see Whittaker (1990), Lauritzen (1996), Edwards
(2000) and, recently, Letac and Massam (2007) and Rajaratnam et al. (2008)). The separation criteria defined on such graphs is a simple separation criteria on undirected graphs:
S ⊆ V separates two disjoint non-empty subsets A and B of V if any path joining a vertex
in A and another in B intersects S.
Other graphical models are represented by graphs with bi-directed edges. These models
are called covariance graph models. The absence of an edge between a given pair of
vertices (α,β) implies that Xα is marginally independent from Xβ, denoted Xα ⊥⊥ Xβ.
The separation criteria in bi-directed graphs can be defined as follows: If A, B and
S are three disjoint subsets of V, where S could be empty, the subset S separates A
and B in the bi-directed graph G if V \ (A ∪ B ∪ S) separates A and B, that is, any
path connecting A and B intersects V \ (A ∪ B ∪ S). In this paper this graph will be
represented by non-directed edges and will be denoted by G0. So the global Markov
property on G0, also called the covariance global Markov property, can be defined as
follows (see Chaudhuri et al. (2007)):

If V \ (A ∪ B ∪ S) separates A and B in G0, then XA ⊥⊥ XB|XS. (2)

Let P be a probability distribution belonging to a certain graphical model (X,G, F ).
The probability distribution P is said to be perfectly Markov to G if the converse of the
global Markov property (1) is also satisfied, that is, for any triple of disjoint non-empty
subsets (A,B,S) where S is not empty,

A⊥CB|S ⇐⇒ XA ⊥⊥ XB|XS. (3)

It was conjectured in Geiger and Pearl (1993) that for any undirected graph G we can
find a Gaussian probability distribution P that is perfectly Markov to G. In the Gaussian


-----



Determining full conditional independence by low-order conditioning 1181

case the perfect Markovianity assumption is equivalent to the following property: For all
non-adjacent vertices α and β in V and for all S ⊆ V \ {α,β} and S ̸= ∅,

S separates α and β ⇐⇒ Xα ⊥⊥ Xβ|XS. (4)

In this paper we will consider an undirected graph G = (V,E) and a probability distribution P that is perfectly Markov to G. Hence, if X = (Xα,α ∈ V )[′] is a random vector
with distribution P, then G satisfies the following condition

(α,β) /∈ E ⇐⇒ Xα ⊥⊥ Xβ | X−αβ,

and if A, B and S are three disjoint non-empty subsets of V

S separates A and B in G ⇐⇒ XA ⊥⊥ XB|XS.

The aim of this paper is to prove the existence of a relationship between the cardinality
of the separators in G and the maximum number of conditioning variables needed to
determine the full conditional independencies in P . We proceed first by defining a new
parameter for undirected graphs, called the “separability order ”. Subsequently we prove
that when we condition on a fixed number of variables equal to this separability order,
the graph that is obtained is exactly the concentration graph.
The paper is organized as follows. Section 2 is devoted to the definition of this parameter and of some properties thereof. In Section 3, we will define a sequence of undirected graphs constructed due to conditional independencies for a given fixed number
k ∈{0,..., |V | − 2}. More precisely, we define the k-graph Gk = (V,Ek) by

(α,β) /∈ Ek ⇐⇒ ∃S ⊆ V \ {α,β} such that |S| = k and Xα ⊥⊥ Xβ|XS. (5)

When k = 0, the conditional independence given an empty set corresponds to the
marginal independence between Xα and Xβ. In the case when k = 0, the corresponding k-graph is then denoted by G0 and constructed using the pairwise Markov property
with respect to bi-directed graphs (see Cox and Wermuth (1996) and Chaudhuri et al.
(2007)). We mean that

α ̸∼G0 β ⇐⇒ Xα ⊥⊥ Xβ.

The graph G0 is also called a covariance graph (see Chaudhuri et al. (2007)). Wille and
B¨uhlman (2006) define a graph called a 0–1 graph, which corresponds to a graph with a
set of edges equal to E0 ∩ E1. We will show later (see Lemma 7) that this graph is equal
to G1. Castello and Roverato (2006) consider so called k-partial graphs G[p]k [= (][V,E]k[p][),]
which are defined as follows:

α ̸∼Gk β ⇐⇒ ∃S ⊆ V \ {α,β} such that |S| ≤ k and Xα ⊥⊥ Xβ|XS. (6)

Obviously for a fixed k, Ek[p] [⊆] [E][k][. We will show later (see Lemma][ 8][) that the][ k][-partial]
graph G[p]k [is equal to][ G][k][. The principle result we prove in this paper (see Theorem][ 4][) is]
that Ek ⊆··· ⊆ E1 ⊆ E0 and that G is equal to Gk, where k is the separability order of
G. The main assumption of this result is that probability distribution P of the random
vector X is perfectly Markov to G.


-----



1182 D. Malouche

#### 2. Separability order

An undirected graph G = (V,E) is a pair of sets where V is the set of vertices and E is
the set of edges that is a subset of V × V, where

(α,β) ∈ E ⇐⇒ (β,α) ∈ E.

For α,β ∈ V, we write α ∼G β when α and β are adjacent in G, that is, (α,β) ∈ E.
A complete graph is a graph where all the vertices are adjacent, and an empty graph
is a graph where the set of edges is empty, that is, E = ∅. A path between a pair of
vertices (α,β) is a sequence of distinct vertices α0,α1,...,αn such that α0 = α, αn = β
and αi ∼G αi+1 for all i = 0,..., (n − 1).
Let U ⊆ V . A subgraph of G induced by U is an undirected graph GU = (U,EU ) such
that EU = U × U ∩ E.
A connected graph is a graph G where any pair of vertices can be joined by a path.
So a connected component of a graph is a subset of V that induces a maximal connected
sub-graph of G, i.e., C ⊆ V is a connected component of G if GC is a connected subgraph
of G and, for any α ∈ V \ C, ∀β ∈ C, there is no path between α and β.
For any non-adjacent vertices α ̸∼G β in a graph G and for any S ⊆ V \ {α,β}, we say
that S is a separator of α and β in G if all the paths between α and β in G intersect
S. Consequently, any S[′] ⊇ S and S[′] ⊆ V \ {α,β} is also a separator of α and β. The
separator S is called a minimal separator of α and β if, for any S[′] ⊆ S and S[′] ̸= S, S[′]

cannot be a separator of α and β. We denote by msG(α,β) the set of minimal separators
of α and β in G. It is clear that the set msG(α,β) = ∅ if and only if α,β are in two
different connected components of G.
Let us now give the definition of the separability order of an undirected graph:

Definition 1. The separability order of a given graph G = (V,E) is

so(G) = max (7)
α̸∼Gβ [min][{|][S][|][,S][ ∈] [ms][G][(][α,β][)][}]

if G is not complete, and so(G) = +∞ if G is complete.

Note that complete graphs have a separability order of infinity. Also, empty graphs,
that is, graphs with no edges between the vertices of G, have a separability order equal
to zero. Conversely, if so(G) = 0 then either G is composed only of complete connected
components or G is an empty graph. We also note that the separability order is purely
a graph-theoretic concept.
We now give an example and proceed to prove basic properties of the separability order
(see Lemma 1).

Example 1. The graph in Figure 1 is an undirected graph containing five vertices. Its
separability order, so(G), is equal to 2. We can easily see that

msG(1, 3) = {{2}}, msG(2, 5) = {{3, 4}},

msG(1, 4) = {{2}}, msG(1, 5) = {{3, 4}, {2}}.


-----



Determining full conditional independence by low-order conditioning 1183

Hence so(G) = 2. The degree of the graph G, d(G), defined in (10) is equal to 3.

Lemma 1. Let G = (V,E) be an undirected graph with connected components

G1 = (V1,E1),...,Gs = (Vs,Es),

with s ≥ 2, and so(G) = m. Then

(i) m = 0 if and only if all the connected components of G are either complete or
singletons.
(ii) m = +∞ if and only if G is complete.
(iii) When m > 0, the following properties are satisfied:
1. There exists a pair (α,β) of non-adjacent vertices and a minimal separator S
of this α and β such that |S| = m.
2. For any pair of non-adjacent vertices there exists a separator of these two
vertices with cardinality equal to m.
(iv) When m > 0, the separability order, so(G), is equal to the maximum separability
order among all its non-complete connected components:

so(G) = max{so(Gl),Gl non-complete}. (8)

Proof. The proof of items (ii) and (iii) follows immediately from Definition 1.

(i) If m = 0, this means that for any α ̸∼G β the only separator of these vertices is the
empty set. Hence α and β belong to different connected components. Moreover,
in each connected component of G there are non-adjacent vertices, since m = 0.
Hence all the connected components of G are either complete or singletons. The
converse of this statement follows easily from the definition of the separability
order.
(iv) Let us define the pairwise separability order of a given pair of vertices α and β

so(α,β|G) = min{|S|,S ∈ msG(α,β)}. (9)

Now let G1,...,Gl be the sequence of non-complete connected components of
G.
Now so(α,β | G) = 0, if α ∈ Gi and β ∈ Gj when i ̸= j and i,j ∈{1,...,l}.

Figure 1. so(G) = 2 and d(G) = 3.


-----



1184 D. Malouche

Thus we can focus on the pairwise separability order of pairs within noncomplete connected components. Then

so(G) = max
α̸∼Gβ [min][{|][S][|][,S][ ∈] [ms][G][(][α,β][)][}]

= max
α,β∈Vk,k=1,...,l α[max]̸∼Gk β [min][{|][S][|][,S][ ∈] [ms][G][k] [(][α,β][)][}]

= max
k=1,...,l α[max]̸∼Gk β [min][{|][S][|][,S][ ∈] [ms][G][k] [(][α,β][)][}]

= max
k=1,...,l [so(][G][k][)][.]                     
It is important to note that the separability order defined in this paper is exactly equal
to the outer connectivity of the missing edges defined by Castello and Roverato (2006)
for connected graphs. We can also prove that the separability order of a non-complete
undirected graph G is always smaller than its degree (Lemma 2 below).

Lemma 2. Let G = (V,E) be a non-complete undirected graph; then

so(G) ≤ d(G),

where

d(G) = max (10)
α∈V [d][(][α][|][G][)][,]

where d(α|G) = |{γ,α ∼G γ}|.

Proof. Let α be a vertex in V, and let V(α|G) be the set of vertices adjacent to α. So
d(α|G) = |V(α|G)|, the degree of α in G. Let β be a vertex non-adjacent to α. It is easy
to see that V(α|G) and V(β|G) are also separators between α and β. Also it is easy to see
that V(α|G) always contains one minimal separator between α and β. For example, the
set of vertices γ denoted by S(α|G) that are simultaneously adjacent to α and belonging
to one path between α and β is a minimal separator of α and β. If we suppress one
vertex from this S(α|G), this latter set will no longer be a separator between α and β.
The same thing also occurs for V(β|G). Hence

min{|S|,S ∈ msG(α,β)} ≤ max(d(α|G),d(β|G)).

Then,

so(G) = max
α̸∼Gβ[{][min][{|][S][|][,S][ ∈] [ms][G][(][α,β][)][}} ≤] α[max]̸∼Gβ [max(][d][(][α][|][G][)][,d][(][β][|][G][))]

= max
α∈V [d][(][α][|][G][) =][ d][(][G][)][.]

So, so(G) ≤ d(G). 
We now define the degree two of an undirected graph.


-----



Determining full conditional independence by low-order conditioning 1185

Figure 2. d2(G) = 1, d(G) = 3, so(G) = 1.

Definition 2. Let G = (V,E) be an undirected graph. The degree two of a vertex in G
is defined by,

d2(α|G) = |{γ,α ∼G γ and d(γ|G) ≥ 2}|

and the degree two of the graph G, d2(G), is

d2(G) = max
α∈V [d][2][(][α][|][G][)][.]

We give an example to illustrate the degree two of a simple undirected graph.

Example 2. The graph in Figure 2 has d2(G) = 1, d(G) = 3, so(G) = 1.

It is easily seen that in practice the computation of the separability order is an NPcomplete problem. The degree two of a graph could be a good upper bound for this
separability order, as this quantity is more easily computable. We prove that so(G) ≤
d2(G) in Lemma 3 below.

Lemma 3. Let G = (V,E) and G[′] = (V,E[′]) be two undirected graphs. Then

(i) if E ⊆ E[′], then d2(G) ≤ d2(G[′]),
(ii) if G is connected and non-complete so(G) ≤ d2(G).

Proof.

(i) First let us define V2(α|G) as follows:

V2(α|G) = {γ,α ∼G γ and d(γ|G) ≥ 2}.

Now for any α ∈ V, V2(α|G) ⊆V2(α|G[′]). Hence |V2(α|G)| ≤|V2(α|G[′])| and thus
d2(α|G) ≤ d2(α|G[′]). This inequality is valid for any α and taking the maximum
on α on either side gives d2(G) ≤ d2(G[′]).
(ii) If so(G) = m, then, using Lemma 1, part (iii), there exist α and β such that α ̸∼G β
and a minimal separator S with cardinality |S| = m. Now V2(α | G) contains the
set S(α|G), which is a minimal separator between α and β (as defined in the proof
of Lemma 2). As S is the smallest minimal separator of α and β,

m ≤|S(α|G)| ≤|V2(α|G)| ≤ d2(G)

                        since d2(G) = maxα∈V |V2(α|G)|. Hence so(G) ≤ d2(G).


-----



1186 D. Malouche

#### 3. Concentration graph by low-order conditioning

As before, let G = (V,E) be an undirected graph with the set of vertices V and the set
of edges E. Let X = ×α∈V Xα be a product probability space. The aim of this section
is to prove the following result.

Theorem 4. Let (X,G, F ) be a concentration graph model and P a probability distribution belonging to F . Let us consider for any k ∈{0,..., |V | − 2} the undirected graph
Gk = (V,Ek) constructed as described in (5):

α ̸∼Gk β ⇐⇒ ∃S ⊆ V \ {α,β} such that |S| = k and Xα ⊥⊥ Xβ|XS.

Suppose that P is perfectly Markov to G and so(G) = m, then

E = Em ⊆ Em−1 ⊆··· ⊆ E1.

Furthermore, if so(G0) < |V | − 2, then E1 ⊆ E0.

Theorem 4 will be proved using the following series of lemmas.

Lemma 5. Let (X,G, F ) be a concentration graph model and let P be a probability
distribution belonging to F . Suppose that G is connected and non-complete and so(G) = m
where m > 0. Suppose also that P is perfectly Markov to G. Then G = Gm, where Gm is
the undirected graph constructed using (5).

Proof. Let α and β be two vertices and let us consider a random vector X = (Xα,α ∈ V )[′]

with distribution P . For any pair (α,β) such that α ̸∼G β, from Lemma 1(iii), there
exists a non-empty subset S with cardinality equal to m that is a separator of α and
β. Using the global Markov property with respect to G (see (1)), we can conclude that
Xα ⊥⊥ Xβ|XS. Using (5) we conclude that α ̸∼Gm β. Since this is valid for any pair (α,β)
we can conclude that Em ⊆ E.
Conversely, suppose that α ̸∼Gm β; then there exists a separator S ⊆ V \ {α,β} with
cardinality m such that Xα ⊥⊥ Xβ|XS. Using the perfect Markovianity property we can
say that S separates α and β in G. Thus we can assert that α ̸∼G β. Since this argument
is valid for any (α,β) we can conclude that E ⊆ Em.
We have altogether shown that Em ⊆ E and E ⊆ Em, hence E = Em, and thus G =
Gm. 
Lemma 6. Let (X,G, F ) be a concentration graph model and let P be a probability distribution belonging to F . For m,k ∈ N, let Gm and Gk be two undirected graphs constructed
using (5). If P is perfectly Markov to G and 1 ≤ m ≤ k ≤|V | − 2 then Ek ⊆ Em.

Proof. Let α and β be two vertices. Let us consider a random vector X = (Xα,α ∈ V )[′]

with distribution P . Suppose that α ̸∼Gm β, then there exists a separator S ⊆ V \ {α,β}
with cardinality m such that Xα ⊥⊥ Xβ|XS. By the perfect Markovianity property we


-----



Determining full conditional independence by low-order conditioning 1187

can conclude that S separates α and β in G. But since k ≥ m, we can find a subset S[′] of
V \ {α,β} containing S with cardinality k such that S[′] is a separator of α and β in G.
Using the global Markov property, we determine that Xα ⊥⊥ Xβ|XS′ . Hence α ̸∼Gk β.
Since α ̸∼Gm β implies that α ̸∼Gk β for any pair (α,β), we can conclude that Ek ⊆
Em. 
Lemma 7. Let P be a probability distribution in X . Let G0 = (V,E0) and G1 = (V,E1)
be two undirected graphs constructed using (5) for k = 0, 1, respectively. If G0 is connected
and so(G0) = m0 < |V | − 2, then E1 ⊆ E0.

Proof. Let α and β be two vertices and let us consider a random vector X = (Xα,α ∈ V )[′]

with distribution P . Suppose that α ̸∼G0 β. By assumption so(G0) = m0, hence there
exists a subset S of V \ {α,β} for which |S| = m0. Let γ ∈ V \ (S ∪{α,β}), which is not
empty because m0 < |V |− 2. Then V \{α,β,γ} contains S and so it is a separator of α and
β in G0. So {γ} m-separates {α} and {β} in G0. Here G0 is seen as an ancestral graph.
Using the covariance global Markov property (2) with respect to bi-directed graphs (see
Cox and Wermuth (1996), Chaudhuri et al. (2007), or Drton and Richardson (2008)), we
can conclude that Xα ⊥⊥ Xβ|Xγ. Then α ̸∼G1 β. Hence E1 ⊆ E0. 
It is easily seen that the results in Lemmas 5–7 lead to the proof of Theorem 4.
Castello and Roverato (2006) prove, by also assuming the perfect Markovianity, that the
concentration graph model G is equal to the k-partial graph G[p]k [as defined in (][6][) when]
k is smaller than the separability order of G, referred to in that paper as the “outer
connectivity of the missing edges”. The result in Theorem 4, however, is based on a
construction of a sequence of nested graphs. It starts from the covariance graph, that is,
G0, the 0-graph, and it becomes stationary and equal to the concentration graph when
the number of conditioning variables is equal to the separability order of the concentration
graph.
In Lemma 8, we show that k-partial graphs and k-graphs are equal when the perfect
Markovianity assumption is satisfied. Next, we give a corollary of Theorem 4. In Corollary 9 we give a condition that allows us to determine the last undirected k-graph in
the sequence of nested graphs obtained due to Theorem 4. This condition is given in
term of the degree two of the k-graphs, not as in Castello and Roverato (2006), where
this condition is expressed as a function of the outer connectivity of connected edges, a
quantity that can be difficult to compute.

Lemma 8. Let X = (Xα,α ∈ V )[′] be a random vector with distribution P belonging to
a graphical model generated by an undirected graph G = (V,E). The undirected graphs
G[p]k [= (][V,E]k[p][)][ and][ G][k][ = (][V,E][k][)][ are respectively the][ k][-partial graph and the][ k][-graph defined]
as in (6) and (5). If P is perfectly Markov w.r.t. to G then for any k ∈{1,..., |V | − 2},
we have E ⊆ Ek = Ek[p][.]

Proof. By definition it is easily seen that α ̸∼Gk β implies α ̸∼G[p]k [β][, hence][ E][k][ ⊆] [E]k[p][.]


-----



1188 D. Malouche

Now let us assume that α ̸∼G[p]k [β][, then there exists][ S][ ⊆] [V][ \ {][α,β][}][,] [|][S][| ≤] [k][ such that]
Xα ⊥⊥ Xβ|XS = (Xγ,γ ∈ S)[′]. If |S| = k, the problem is solved. If |S| < k, using the perfect
Markovianity of P we can say that S separates α and β in G. Then we can construct
an S[′] ⊆ V \ {α,β} with |S[′]| = k, S[′] ⊇ S such that S[′] separates α and β in G. We can
now use the global Markov property (see (1)), to assert that Xα ⊥⊥ Xβ|XS′ and hence
α ̸∼Gk β. We can therefore deduce that Ek[p] [⊆] [E][k][. Since][ E][k][ ⊆] [E]k[p] [and][ E]k[p] [⊆] [E][k][ we can]
conclude that Ek[p] [=][ E][k][. The inclusion][ E][ ⊆] [E][k][ has already been proved in Theorem][ 4][.][ □]

We can also deduce the following corollary from Theorem 4.

Corollary 9. Let (X,G, F ) be a concentration graphical model such that G is a noncomplete connected graph and let P be a probability distribution belonging to F . Let us
consider for any k ∈{0,..., |V | − 2} the undirected graph Gk = (V,Ek) constructed as
described in (5). Let us assume that P is perfectly Markov to the graphical model G and
d2(G) ≤|V | − 2. Then there exists k ∈{1,..., |V | − 2} such that

d2(Gk) ≤ k and G = Gk. (11)

Proof. Let us assume that for all k ∈{1,..., |V | − 2} that d2(Gk) > k. This implies
for example that d2(G|V |−2) > |V | − 2. As the concentration graph G is exactly the
G|V |−2 we deduce that d2(G) > |V | − 2 which is a contradiction with our assumption,
i.e., d2(G) ≤|V | − 2. Hence there exists an integer k such that d2(Gk) ≤ k. But E ⊆ Ek
and, applying Lemma 3(ii), we deduce that so(G) = m ≤ d2(G) ≤ d2(Gk) ≤ k.
Using Theorem 4, as k ≥ m, we can conclude that G = Gm = Gk.  
Corollary 9 can be useful if we wish to determine the concentration graph from a given
data set when assuming perfect Markovianity. It is sufficient to check the degree two of
each estimated k-graph.

#### 4. Conclusion

In this paper we have proved that a concentration graph model can be determined using
a limited number of conditioning variables. The cardinality of this limited subset is
determined by looking at the structure of the undirected graph associated with the
corresponding distribution global Markov property. Certainly the perfect Markovianity
assumption is also needed for our result to be valid. Our result remains true for both
continuous and discrete distributions.
Our result can also be used as a justification of the estimation of graphical models by low-order conditioning such as using the PC algorithm (see Spirtes et al.
(2000), Kalisch and B¨uhlmann (2007), Kjærulff and Madsen (2007)), the 0–1 procedure
(see Friedman et al. (2000) and Wille and B¨uhlman (2006)), or the qp-procedure (see
Castello and Roverato (2006)). Practical applications of these procedures are useful when
the number of observations are far fewer than the number of variables. We first estimate


-----



Determining full conditional independence by low-order conditioning 1189

the sequence of nested graphs Gk starting from k = 0 (test on marginal independence
between variables) and proceed accordingly. This procedure is terminated when the number of conditioning variables becomes greater than the degree two of the estimated graph
Gk. In this sense the theory above has tremendous scope for applications.

#### References

Castelo, R. and Roverato, A. (2006). A robust procedure for Gaussian graphical models search
for microarray data with p larger than n. J. Mach. Learn. Res. 57 2621–2650.
Chaudhuri, S., Drton, M. and Richardson, R.T. (2007). Estimation a covariance matrix with
[zeros. Biometrika 94 199–216. MR2307904](http://www.ams.org/mathscinet-getitem?mr=2307904)
Cox, D.R. and Wermuth, N. (1996). Multivariate Depencies: Models, Analysis & Interpretations.
[London: Chapman & Hall. MR1456990](http://www.ams.org/mathscinet-getitem?mr=1456990)
Dempster, A. (1972). Covariance selection. Biometrics 28 157–175.
Drton, M. and Richardson, T. (2008). Graphical methods for efficient likelihood inference in
[Gaussian covariance models. J. Mach. Learn. 9 893–914. MR2417257](http://www.ams.org/mathscinet-getitem?mr=2417257)
[Edwards, D. (2000). Introduction to Graphical Modelling. New York: Springer. MR1880319](http://www.ams.org/mathscinet-getitem?mr=1880319)
Friedman, N., Linial, M., Nachman, I. and Pe’er, D. (2000). Using Bayesian networks to analyse
expression data. J. Comput. Biol. 7(3–4) 601–620.
Geiger, D. and Pearl, J. (1993). Logical and algorithmic properties of conditional independence
[and graphical models. Ann. Statist. 21 2001–2021. MR1245778](http://www.ams.org/mathscinet-getitem?mr=1245778)
Kalisch, M. and B¨uhlmann, P. (2007). Estimating high-dimensional directed acyclic graphs with
the PC-algorithm. J. Mach. Learn. Res. 8 613–636.
Kjærulff, U.B. and Madsen, A.L. (2007). Bayesian Networks and Influence Diagrams. New York:
[Springer. MR2371308](http://www.ams.org/mathscinet-getitem?mr=2371308)
[Lauritzen, S.L. (1996). Graphical Models. New York: Oxford Univ. Press. MR1419991](http://www.ams.org/mathscinet-getitem?mr=1419991)
Letac, G. and Massam, H. (2007). Wishart distributions on decomposable graphs. Ann. Statist.
[35 1278–1323. MR2341706](http://www.ams.org/mathscinet-getitem?mr=2341706)
Rajaratnam, B., Massam, H. and Carvalho, C. (2008). Flexible covariance estimation in graph[ical models. Ann. Statist. 36 2818–2849. MR2485014](http://www.ams.org/mathscinet-getitem?mr=2485014)
Spirtes, P., Glymour, C. and Scheines, R. (2000). Causation, Prediction and Search, 2nd ed.
[Cambridge, MA: MIT Press. MR1815675](http://www.ams.org/mathscinet-getitem?mr=1815675)
Whittaker, J. (1990). Graphical Models in Applied Multivariate Statistics. Cambridge, MA: Wi[ley. MR1112133](http://www.ams.org/mathscinet-getitem?mr=1112133)
Wille, A. and B¨uhlman, P. (2006). Low-order conditional independence graphs for inferring
[genetic network. Stat. Appl. Genet. Mol. Biol. 5 1–32. MR2221304](http://www.ams.org/mathscinet-getitem?mr=2221304)

Received May 2008 and revised February 2009


-----

