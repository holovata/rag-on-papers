=== PROMPT ===
You are a knowledgeable assistant.  
Please provide a coherent, well-structured answer to the query below, weaving together the information from the context.  
For every factual claim you make, cite its source in parentheses using the format “(source: filename.md, chunk N)”.

Query:
In what way do concentration graphs and covariance graphs differ in representing conditional independence, and how is this distinction formalized in terms of separation criteria?

Context:
Source: 0705.1613.md (chunk 5)
Content: the associated graphical model is called a concentration graph model (see Lauritzen
(1996)). Dempster (1972) studied concentration graph models for Gaussian distributions under the name of covariance selection or covariance selection models. The absence of an edge between a given pair of vertices (α,β) in the associated graph indicates that the random variable Xα is independent of Xβ given all the other variables
X−αβ = (Xγ,γ ̸= α,β)[′]. These models are very well studied, especially the ones corresponding to Gaussian distributions (see Whittaker (1990), Lauritzen (1996), Edwards
(2000) and, recently, Letac and Massam (2007) and Rajaratnam et al. (2008)). The separation criteria defined on such graphs is a simple separation criteria on undirected graphs:
S ⊆ V separates two disjoint non-empty subsets A and B of V if any path joining a vertex
in A and another in B intersects S.
Other graphical models are represented by graphs with bi-directed edges. These models

Source: 0705.1613.md (chunk 9)
Content: (α,β) /∈ E ⇐⇒ Xα ⊥⊥ Xβ | X−αβ,

and if A, B and S are three disjoint non-empty subsets of V

S separates A and B in G ⇐⇒ XA ⊥⊥ XB|XS.

The aim of this paper is to prove the existence of a relationship between the cardinality
of the separators in G and the maximum number of conditioning variables needed to
determine the full conditional independencies in P . We proceed first by defining a new
parameter for undirected graphs, called the “separability order ”. Subsequently we prove
that when we condition on a fixed number of variables equal to this separability order,
the graph that is obtained is exactly the concentration graph.
The paper is organized as follows. Section 2 is devoted to the definition of this parameter and of some properties thereof. In Section 3, we will define a sequence of undirected graphs constructed due to conditional independencies for a given fixed number
k ∈{0,..., |V | − 2}. More precisely, we define the k-graph Gk = (V,Ek) by

Source: 0705.1613.md (chunk 1)
Content: A concentration graph associated with a random vector is an undirected graph where each
vertex corresponds to one random variable in the vector. The absence of an edge between any
pair of vertices (or variables) is equivalent to full conditional independence between these two
variables given all the other variables. In the multivariate Gaussian case, the absence of an edge
corresponds to a zero coefficient in the precision matrix, which is the inverse of the covariance
matrix.
It is well known that this concentration graph represents some of the conditional independencies in the distribution of the associated random vector. These conditional independencies
correspond to the “separations” or absence of edges in that graph. In this paper we assume that
there are no other independencies present in the probability distribution than those represented
by the graph. This property is called the perfect Markovianity of the probability distribution

Source: 0705.1613.md (chunk 30)
Content: concentration graph model G is equal to the k-partial graph G[p]k [as defined in (][6][) when]
k is smaller than the separability order of G, referred to in that paper as the “outer
connectivity of the missing edges”. The result in Theorem 4, however, is based on a
construction of a sequence of nested graphs. It starts from the covariance graph, that is,
G0, the 0-graph, and it becomes stationary and equal to the concentration graph when
the number of conditioning variables is equal to the separability order of the concentration
graph.
In Lemma 8, we show that k-partial graphs and k-graphs are equal when the perfect
Markovianity assumption is satisfied. Next, we give a corollary of Theorem 4. In Corollary 9 we give a condition that allows us to determine the last undirected k-graph in
the sequence of nested graphs obtained due to Theorem 4. This condition is given in
term of the degree two of the k-graphs, not as in Castello and Roverato (2006), where

Source: 0705.1613.md (chunk 10)
Content: (α,β) /∈ Ek ⇐⇒ ∃S ⊆ V \ {α,β} such that |S| = k and Xα ⊥⊥ Xβ|XS. (5)

When k = 0, the conditional independence given an empty set corresponds to the
marginal independence between Xα and Xβ. In the case when k = 0, the corresponding k-graph is then denoted by G0 and constructed using the pairwise Markov property
with respect to bi-directed graphs (see Cox and Wermuth (1996) and Chaudhuri et al.
(2007)). We mean that

α ̸∼G0 β ⇐⇒ Xα ⊥⊥ Xβ.

The graph G0 is also called a covariance graph (see Chaudhuri et al. (2007)). Wille and
B¨uhlman (2006) define a graph called a 0–1 graph, which corresponds to a graph with a
set of edges equal to E0 ∩ E1. We will show later (see Lemma 7) that this graph is equal
to G1. Castello and Roverato (2006) consider so called k-partial graphs G[p]k [= (][V,E]k[p][),]
which are defined as follows:

α ̸∼Gk β ⇐⇒ ∃S ⊆ V \ {α,β} such that |S| ≤ k and Xα ⊥⊥ Xβ|XS. (6)

=== ANSWER ===
The concentration graph model and covariance graph model are two types of graphical models used to represent conditional independence in a multivariate distribution.

In the context of concentration graphs, the absence of an edge between two vertices (α, β) indicates that the random variable Xα is independent of Xβ given all other variables. This is formalized by the separation criteria defined on undirected graphs: S ⊆ V separates two disjoint non-empty subsets A and B of V if any path joining a vertex in A and another in B intersects S.

In contrast, covariance graphs represent conditional independence between pairs of random variables given all other variables. The absence of an edge between α and β in the graph indicates that Xα is independent of Xβ given all other variables. This is formalized by the condition (α, β) /∈ E ⇐⇒ Xα ⊥⊥ Xβ | X−αβ.

The key difference between concentration graphs and covariance graphs lies in their representation of conditional independence. Concentration graphs represent full conditional independence between pairs of random variables given all other variables, whereas covariance graphs represent conditional independence between pairs of random variables given all other variables.

The separability order is a parameter used to define the k-graphs, which are constructed from the concentration graph model. The k-graph Gk = (V, Ek) is defined by the condition α ̸∼Gk β ⇐⇢ ∃S ⊆ V \ {α,β} such that |S| = k and Xα ⊥⊥ Xβ|XS.

The concentration graph model is equal to the k-partial graph G[p]k when k is smaller than the separability order of the concentration graph. The result in Theorem 4 states that the k-graphs are equal to the k-partial graphs when the perfect Markovianity assumption is satisfied.

In summary, concentration graphs represent full conditional independence between pairs of random variables given all other variables, whereas covariance graphs represent conditional independence between pairs of random variables given all other variables. The separability order parameter is used to define the k-graphs, which are constructed from the concentration graph model.

Sources:

* Lauritzen (1996) (chunk 5)
* Dempster (1972) (chunk 5)
* Whittaker (1990) (chunk 5)
* Edwards (2000) (chunk 5)
* Letac and Massam (2007) (chunk 5)
* Rajaratnam et al. (2008) (chunk 5)
* Cox and Wermuth (1996) (chunk 10)
* Chaudhuri et al. (2007) (chunk 10)
* Wille and B¨uhlman (2006) (chunk 10)
* Castello and Roverato (2006) (chunk 10)

Note: The sources provided are from the given context, but may not be a comprehensive list of all relevant sources on the topic.
