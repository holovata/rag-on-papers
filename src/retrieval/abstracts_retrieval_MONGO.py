#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Query arXiv papers stored in MongoDB Atlas by cosine-similarity using OpenAI embeddings.
ĞŸÑ–Ğ´Ñ‚Ñ€Ğ¸Ğ¼ÑƒÑ” Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ñ–Ñ Ğ¿Ğ¾ Ğ¿Ğ¾Ñ€Ğ¾Ğ³Ñƒ min_similarity.
"""

import sys
import os
from pymongo.mongo_client import MongoClient
from pymongo.server_api import ServerApi
import numpy as np
from dotenv import load_dotenv
from langchain_openai import OpenAIEmbeddings

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ĞµĞ½Ğ½Ñ Ğ·Ğ¼Ñ–Ğ½Ğ½Ğ¾Ğ³Ğ¾ ÑĞµÑ€ĞµĞ´Ğ¾Ğ²Ğ¸Ñ‰Ğ°
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

load_dotenv()

MONGODB_URI = os.getenv("MONGODB_URI")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

if not OPENAI_API_KEY:
    print("âŒ OPENAI_API_KEY Ğ½Ğµ Ğ²ÑÑ‚Ğ°Ğ½Ğ¾Ğ²Ğ»ĞµĞ½Ğ¾ Ğ² ÑĞµÑ€ĞµĞ´Ğ¾Ğ²Ğ¸Ñ‰Ñ–!", file=sys.stderr)
    sys.exit(1)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞŸÑ–Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ½Ñ Ğ´Ğ¾ MongoDB Atlas
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

client = MongoClient(
    MONGODB_URI,
    server_api=ServerApi("1"),
    serverSelectionTimeoutMS=20000,
    socketTimeoutMS=20000
)
try:
    client.admin.command("ping")
except Exception as e:
    print(f"âŒ ĞĞµ Ğ²Ğ´Ğ°Ğ»Ğ¾ÑÑ Ğ¿Ñ–Ğ´ĞºĞ»ÑÑ‡Ğ¸Ñ‚Ğ¸ÑÑ Ğ´Ğ¾ MongoDB: {e}")
    sys.exit(1)

db = client["arxiv_db"]
papers_col = db["arxiv_metadata"]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# OpenAI Embedding Initialization
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

embed_model = OpenAIEmbeddings(model="text-embedding-3-small")

def generate_query_embedding(query: str) -> list[float] | None:
    """
    Generate an embedding vector for the user's query using OpenAI.
    Returns a list of floats, or None on failure.
    """
    try:
        return embed_model.embed_query(query)
    except Exception as e:
        print(f"âŒ Error generating query embedding: {e}")
        return None

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ĞÑĞ½Ğ¾Ğ²Ğ½Ğ° Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ Ğ¿Ğ¾ÑˆÑƒĞºÑƒ
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def get_top_relevant_articles(
    query: str,
    top_n: int = 3,
    min_similarity: float = 0.0,
    num_candidates: int = 150
) -> list[dict]:
    """
    Retrieve up to top_n articles whose vector-similarity â‰¥ min_similarity.
    Ğ’Ğ¸ĞºĞ¾Ñ€Ğ¸ÑÑ‚Ğ¾Ğ²ÑƒÑ” $vectorSearch (MongoDB Atlas Search) Ñ– Ñ„Ñ–Ğ»ÑŒÑ‚Ñ€ÑƒÑ” Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¸.
    """
    qe = generate_query_embedding(query)
    if qe is None:
        print("âš  Failed to generate embedding for query.")
        return []

    pipeline = [
        {
            "$vectorSearch": {
                "index":         "embedding_vector_index",
                "path":          "embedding",
                "queryVector":   qe,
                "numCandidates": num_candidates,
                "limit":         num_candidates
            }
        },
        {
            "$project": {
                "_id":       1,
                "title":     1,
                "authors":   1,
                "abstract":  1,
                "score":     {"$meta": "vectorSearchScore"}
            }
        }
    ]

    try:
        cursor = papers_col.aggregate(pipeline, maxTimeMS=45000)
    except Exception as e:
        print(f"âŒ Vector search failed: {e}")
        return []

    candidates = []
    for doc in cursor:
        score = float(doc.get("score", 0.0))
        if score >= min_similarity:
            candidates.append({
                "id":         doc["_id"],
                "title":      doc.get("title", "N/A"),
                "authors":    doc.get("authors", "N/A"),
                "abstract":   (doc.get("abstract", "")[:500] + "...") if doc.get("abstract") else "No abstract",
                "similarity": score,
                "pdf_url":    f"https://arxiv.org/pdf/{doc['_id']}.pdf"
            })

    if not candidates:
        print(f"âš  No articles with similarity â‰¥ {min_similarity:.2f}")
        return []

    candidates.sort(key=lambda x: x["similarity"], reverse=True)
    results = candidates[:top_n]
    print(f"ğŸ” Found {len(results)} articles (max similarity = {candidates[0]['similarity']:.4f}).")
    return results

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Ğ†Ğ½Ñ‚ĞµÑ€Ğ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¸Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if __name__ == "__main__":
    user_query = input("ğŸ” Ğ’Ğ²ĞµĞ´Ñ–Ñ‚ÑŒ Ğ¿Ğ¾ÑˆÑƒĞºĞ¾Ğ²Ğ¸Ğ¹ Ğ·Ğ°Ğ¿Ğ¸Ñ‚: ").strip()
    if not user_query:
        print("âš  ĞŸĞ¾Ñ€Ğ¾Ğ¶Ğ½Ñ–Ğ¹ Ğ·Ğ°Ğ¿Ğ¸Ñ‚. Ğ—Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ½Ñ.")
        sys.exit(0)

    top_articles = get_top_relevant_articles(
        query=user_query,
        top_n=5,
        min_similarity=0.6,
        num_candidates=150
    )

    if top_articles:
        print("\nğŸ“„ ĞĞ°Ğ¹Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ–ÑˆÑ– ÑÑ‚Ğ°Ñ‚Ñ‚Ñ–:")
        for i, art in enumerate(top_articles, 1):
            print(f"\n#{i}")
            print(f"ID:         {art['id']}")
            print(f"Title:      {art['title']}")
            print(f"Authors:    {art['authors']}")
            print(f"Similarity: {art['similarity']:.6f}")
            print(f"Abstract:   {art['abstract']}")
            print(f"PDF:        {art['pdf_url']}")
    else:
        print("ğŸ˜• ĞÑ–Ñ‡Ğ¾Ğ³Ğ¾ Ğ½Ğµ Ğ·Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾.")
